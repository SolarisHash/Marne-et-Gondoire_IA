from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import PlainTextResponse, StreamingResponse
import uvicorn
import os
from dotenv import load_dotenv
from datetime import datetime
from typing import List, Optional
import json
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
import queue
import threading

# Charger les variables d'environnement
load_dotenv()
progress_updates = {}  # session_id -> queue


# Configuration de l'application
app = FastAPI(
    title="MG Data MCP Server",
    description="Serveur MCP pour l'enrichissement de donn√©es Marne & Gondoire",
    version="0.2.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Routes principales
@app.get("/")
async def root():
    """Point d'entr√©e principal du serveur"""
    return {
        "message": "Serveur MCP Marne & Gondoire - Enrichissement de donn√©es",
        "version": "0.2.0",
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "project": "Marne & Gondoire",
        "capabilities": [
            "üìä Analyse fichiers Excel/CSV",
            "üîó Enrichissement LinkedIn", 
            "üìà Rapports de traitement",
            "üéØ D√©tection automatique des gaps"
        ],
        "available_endpoints": [
            "/health",
            "/analyze", 
            "/test-basic",
            "/info"
        ]
    }

@app.get("/health")
async def health_check():
    """V√©rification de l'√©tat du serveur"""
    return {
        "status": "healthy",
        "service": "mg-data-mcp",
        "uptime": "running",
        "components": {
            "server": "‚úÖ Actif",
            "basic_tools": "‚úÖ Disponible",
            "file_system": "‚úÖ Accessible"
        }
    }

@app.get("/analyze-advanced")
async def analyze_advanced():
    """Analyse avanc√©e avec d√©tection pr√©cise des opportunit√©s LinkedIn"""
    try:
        # Import direct du fichier
        import os
        import importlib.util
        
        # Chemin vers le fichier data_analyzer.py
        current_dir = os.path.dirname(os.path.abspath(__file__))
        analyzer_path = os.path.join(current_dir, "tools", "data_analyzer.py")
        
        if not os.path.exists(analyzer_path):
            return {
                "error": f"Fichier non trouv√©: {analyzer_path}",
                "current_dir": current_dir,
                "tools_exists": os.path.exists(os.path.join(current_dir, "tools"))
            }
        
        # Charger le module dynamiquement
        spec = importlib.util.spec_from_file_location("data_analyzer", analyzer_path)
        data_analyzer = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(data_analyzer)
        
        # Appeler la fonction
        result = data_analyzer.analyze_data_gaps_advanced()
        return result
        
    except Exception as e:
        return {
            "error": f"Erreur: {str(e)}",
            "type": type(e).__name__,
            "current_dir": os.path.dirname(os.path.abspath(__file__))
        }

@app.get("/test-basic")
async def test_basic_functionality():
    """Test des fonctionnalit√©s de base"""
    try:
        from mcp_server.tools.basic import get_project_status
        status = get_project_status()
        
        return {
            "basic_tools": "‚úÖ OK",
            "project_status": status,
            "message": "Tests de base r√©ussis"
        }
    except Exception as e:
        return {
            "basic_tools": "‚ùå Erreur",
            "error": str(e)
        }

@app.get("/info")
async def project_info():
    """Informations d√©taill√©es sur le projet"""
    return {
        "project": "Marne & Gondoire", 
        "description": "Plateforme d'enrichissement de donn√©es d'entreprises",
        "version": "0.2.0",
        "status": "configuration en cours",
        "next_steps": [
            "1. V√©rifier que le fichier Excel est dans data/raw/",
            "2. Installer pandas: pip install pandas openpyxl",
            "3. Cr√©er les outils d'analyse avanc√©e",
            "4. Tester l'enrichissement LinkedIn"
        ]
    }

@app.get("/analyze-advanced")
async def analyze_advanced():
    """Analyse avanc√©e avec d√©tection pr√©cise des opportunit√©s LinkedIn"""
    try:
        from mcp_server.tools.data_analyzer import analyze_data_gaps_advanced
        result = analyze_data_gaps_advanced()
        return result
    except ImportError as e:
        return {
            "error": f"Module d'analyse avanc√©e non disponible: {str(e)}",
            "solution": "Cr√©ez le fichier mcp_server/tools/data_analyzer.py"
        }
    except Exception as e:
        return {
            "error": f"Erreur analyse avanc√©e: {str(e)}"
        }

@app.get("/analyze-color", response_class=PlainTextResponse)
async def analyze_with_colors():
    """Version avec codes couleur ANSI pour terminal"""
    try:
        import os
        import importlib.util
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        analyzer_path = os.path.join(current_dir, "tools", "data_analyzer.py")
        
        spec = importlib.util.spec_from_file_location("data_analyzer", analyzer_path)
        data_analyzer = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(data_analyzer)
        
        result = data_analyzer.analyze_data_gaps_advanced()
        
        if "error" in result:
            return f"\033[91m‚ùå ERREUR: {result['error']}\033[0m"
        
        # Codes couleur ANSI
        RED = '\033[91m'
        GREEN = '\033[92m'
        YELLOW = '\033[93m'
        BLUE = '\033[94m'
        PURPLE = '\033[95m'
        CYAN = '\033[96m'
        WHITE = '\033[97m'
        BOLD = '\033[1m'
        END = '\033[0m'
        
        report = f"""
{BOLD}{CYAN}üöÄ ANALYSE MARNE & GONDOIRE{END}
{CYAN}{'='*50}{END}

{BOLD}üìÅ FICHIER:{END}
  {result['file_info']['name']}
  {GREEN}{result['file_info']['total_companies']:,} entreprises{END} | {result['file_info']['total_columns']} colonnes

{BOLD}üìä VUE D'ENSEMBLE:{END}
  Compl√©tion moyenne: {GREEN if result['global_stats']['average_completion_rate'] > 70 else YELLOW}{result['global_stats']['average_completion_rate']}%{END}
  Champs manquants: {RED}{result['global_stats']['total_missing_fields']:,}{END}

{BOLD}{RED}üî• TOP OPPORTUNIT√âS LINKEDIN:{END}
"""
        
        for i, priority in enumerate(result['top_priorities'][:3], 1):
            priority_color = RED if "CRITIQUE" in priority['priority'] else YELLOW if "HAUTE" in priority['priority'] else GREEN
            report += f"""
                {BOLD}{i}. {priority['column']}{END}
                {RED}Manquants: {priority['missing_count']:,}{END} | {GREEN}Gain: {priority['estimated_gain']:,}{END}
                {priority_color}{priority['priority']}{END}
            """

        # Sites web sp√©cifiquement
        site_priority = result['top_priorities'][0]
        if 'site' in site_priority['column'].lower():
            report += f"""
                {BOLD}{GREEN}üí∞ JACKPOT SITES WEB:{END}
                {RED}{site_priority['missing_count']:,}{END} sites manquants sur {result['file_info']['total_companies']:,}
                {GREEN}{site_priority['estimated_gain']:,}{END} sites r√©cup√©rables via LinkedIn
                {YELLOW}Temps estim√©: {result['batch_strategy']['estimated_processing_time']}{END}
            """

        report += f"""
                {BOLD}{BLUE}üöÄ COMMANDES RAPIDES:{END}
                Test:       {CYAN}curl http://localhost:8080/enrich?test_mode=true{END}
                Sites web:  {CYAN}curl -X POST http://localhost:8080/enrich-websites{END}
                Rapport:    {CYAN}curl http://localhost:8080/analyze-report{END}

                {BOLD}{GREEN}‚ú® Pr√™t pour l'enrichissement !{END}
            """
        
        return report
        
    except Exception as e:
        return f"\033[91m‚ùå ERREUR: {str(e)}\033[0m"


@app.get("/analyze-complete", response_class=PlainTextResponse)
async def analyze_complete():
    """Analyse compl√®te de TOUTES les colonnes avec rapport d√©taill√©"""
    try:
        # Import direct du module
        import os
        import importlib.util
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        analyzer_path = os.path.join(current_dir, "tools", "data_analyzer.py")
        
        if not os.path.exists(analyzer_path):
            return f"‚ùå Fichier data_analyzer.py non trouv√©"
        
        # Charger le module
        spec = importlib.util.spec_from_file_location("data_analyzer", analyzer_path)
        data_analyzer = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(data_analyzer)
        
        # Lancer l'analyse compl√®te
        result = data_analyzer.analyze_complete_file()
        
        if "error" in result:
            return f"‚ùå ERREUR: {result['error']}"
        
        # Formatage du rapport complet - CORRIG√â
        report = f"""
üîç ANALYSE COMPL√àTE - TOUTES COLONNES
{'='*70}

üìÅ FICHIER ANALYS√â
  Nom: {result['file_info']['filename']}
  Lignes: {result['file_info']['total_rows']:,}
  Colonnes: {result['file_info']['total_columns']}
  Taille: {result['file_info']['file_size_mb']} MB

üìä STATISTIQUES GLOBALES
{'='*70}
  Cellules totales: {result['global_stats']['total_cells']:,}
  Cellules remplies: {result['global_stats']['filled_cells']:,}
  Cellules vides: {result['global_stats']['missing_cells']:,}
  Taux de compl√©tion: {result['global_stats']['overall_completion_rate']}%
  Moyenne vides/ligne: {result['global_stats']['avg_missing_per_row']}

üìã ANALYSE D√âTAILL√âE - TOUTES LES COLONNES
{'='*70}
"""
        
        # Analyser toutes les colonnes
        columns = result['all_columns_analysis']
        
        # Trier par taux de compl√©tion (plus vides en premier)
        sorted_columns = sorted(
            columns.items(),
            key=lambda x: x[1]['completion_rate']
        )
        
        for i, (col_name, data) in enumerate(sorted_columns, 1):
            # Ic√¥ne selon le taux de compl√©tion
            if data['completion_rate'] >= 95:
                icon = "‚úÖ"
            elif data['completion_rate'] >= 80:
                icon = "üü¢"
            elif data['completion_rate'] >= 50:
                icon = "üü°"
            else:
                icon = "üî¥"
            
            # Type d√©tect√©
            col_type = data['detected_type']['category']
            
            # Enrichissement possible ?
            enrichable = "üöÄ" if data['enrichment_potential']['is_enrichable'] else "‚ö™"
            
            report += f"""
{icon} {i:2d}. {col_name}
     Compl√©tion: {data['completion_rate']:5.1f}% ({data['present_count']:,}/{data['present_count'] + data['missing_count']:,})
     Manquants: {data['missing_count']:,}
     Type d√©tect√©: {col_type}
     {enrichable} Enrichissement: {data['enrichment_potential']['priority']} (gain: {data['enrichment_potential']['estimated_gain']:,})
     √âchantillons: {' | '.join(data['content_analysis']['sample_values'])}
"""
        
        # Opportunit√©s d'enrichissement
        opportunities = result['enrichment_opportunities']
        
        if opportunities:
            report += f"""
üéØ OPPORTUNIT√âS D'ENRICHISSEMENT
{'='*70}
"""
            for i, (col, data) in enumerate(list(opportunities.items())[:10], 1):
                report += f"""
{i:2d}. {col}
    üéØ Manquants: {data['missing_count']:,} | Gain estim√©: {data['estimated_gain']:,}
    üìä Priorit√©: {data['priority']} | Sources: {', '.join(data['sources'])}
"""
        else:
            report += f"""
‚úÖ AUCUNE OPPORTUNIT√â D'ENRICHISSEMENT MAJEURE
{'='*70}
Vos donn√©es sont d√©j√† tr√®s compl√®tes !
"""
        
        # √âchantillon de donn√©es
        report += f"""
üß™ √âCHANTILLON DE DONN√âES
{'='*70}
"""
        
        for i, sample in enumerate(result['sample_data'], 1):
            report += f"\n{i}. "
            sample_parts = []
            for key, value in sample.items():
                sample_parts.append(f"{key}: {value}")
            report += " | ".join(sample_parts)
        
        # Commandes utiles
        report += f"""

üöÄ COMMANDES UTILES
{'='*70}
  Analyse JSON: curl http://localhost:8080/analyze-advanced
  Documentation: http://localhost:8080/docs

üéâ ANALYSE TERMIN√âE - {result['file_info']['total_columns']} colonnes analys√©es !
"""
        
        return report
        
    except Exception as e:
        return f"""
‚ùå ERREUR LORS DE L'ANALYSE COMPL√àTE
{'='*50}
Erreur: {str(e)}
Type: {type(e).__name__}

L'analyseur fonctionne (voir les logs), mais erreur de formatage.
V√©rifiez l'endpoint analyze-complete dans main.py
"""
    
# ============================================================================
# ENDPOINT POUR ANALYSE RAPIDE (colonnes principales seulement)
# ============================================================================

@app.get("/analyze-summary", response_class=PlainTextResponse)
async def analyze_summary():
    """Analyse rapide avec r√©sum√© des colonnes les plus importantes"""
    try:
        import os
        import importlib.util
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        analyzer_path = os.path.join(current_dir, "tools", "data_analyzer.py")
        
        spec = importlib.util.spec_from_file_location("data_analyzer", analyzer_path)
        data_analyzer = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(data_analyzer)
        
        result = data_analyzer.analyze_complete_file()
        
        if "error" in result:
            return f"‚ùå ERREUR: {result['error']}"
        
        # Rapport condens√©
        report = f"""
üìä R√âSUM√â D'ANALYSE - {result['file_info']['name']}
{'='*60}

üìà VUE D'ENSEMBLE
  Fichier: {result['file_info']['total_rows']:,} lignes √ó {result['file_info']['total_columns']} colonnes
  Qualit√©: {result['data_quality_report']['overall_grade']}
  Compl√©tion: {result['data_quality_report']['average_completion']}%

üéØ TOP 5 OPPORTUNIT√âS D'ENRICHISSEMENT
{'='*60}
"""
        
        # Top 5 des opportunit√©s
        opportunities = list(result['enrichment_opportunities'].items())[:5]
        
        if opportunities:
            for i, (col, data) in enumerate(opportunities, 1):
                report += f"""
{i}. {col}
   üî¥ Manquants: {data['missing_count']:,} | üéØ R√©cup√©rables: {data['estimated_gain']:,}
   üí™ Faisabilit√©: {data['feasibility_score']}% | Sources: {data['sources'][0]}
"""
        else:
            report += "\n‚úÖ Aucune opportunit√© majeure d√©tect√©e - donn√©es bien compl√®tes !"
        
        # Colonnes parfaites
        perfect_columns = [col for col, data in result['complete_column_analysis'].items() 
                          if data['completion_rate'] == 100.0]
        
        report += f"""
‚úÖ COLONNES PARFAITES (100% compl√®tes)
{'='*60}
  {len(perfect_columns)} colonnes: {', '.join(perfect_columns[:5])}{"..." if len(perfect_columns) > 5 else ""}

üöÄ ACTIONS RAPIDES
{'='*60}
  Analyse compl√®te: curl http://localhost:8080/analyze-complete
  Test enrichissement: curl -X POST "http://localhost:8080/enrich?test_mode=true"
"""
        
        return report
        
    except Exception as e:
        return f"‚ùå ERREUR: {str(e)}"

# ============================================================================
# ENDPOINT POUR COMPARAISON AVANT/APR√àS ENRICHISSEMENT
# ============================================================================

@app.get("/analyze-comparison", response_class=PlainTextResponse)  
async def analyze_comparison():
    """Compare l'√©tat actuel avec le potentiel apr√®s enrichissement"""
    try:
        import os
        import importlib.util
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        analyzer_path = os.path.join(current_dir, "tools", "data_analyzer.py")
        
        spec = importlib.util.spec_from_file_location("data_analyzer", analyzer_path)
        data_analyzer = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(data_analyzer)
        
        result = data_analyzer.analyze_complete_file()
        
        if "error" in result:
            return f"‚ùå ERREUR: {result['error']}"
        
        report = f"""
üìä COMPARAISON AVANT/APR√àS ENRICHISSEMENT
{'='*70}

üìÅ {result['file_info']['name']} - {result['file_info']['total_rows']:,} entreprises
"""
        
        # Analyse avant/apr√®s pour chaque colonne enrichissable
        opportunities = result['enrichment_opportunities']
        
        if opportunities:
            total_current = 0
            total_potential = 0
            
            report += f"""
üîÑ PROJECTION D'ENRICHISSEMENT PAR COLONNE
{'='*70}
"""
            
            for col, data in opportunities.items():
                current_filled = result['file_info']['total_rows'] - data['missing_count']
                potential_filled = current_filled + data['estimated_gain']
                
                current_rate = (current_filled / result['file_info']['total_rows']) * 100
                potential_rate = (potential_filled / result['file_info']['total_rows']) * 100
                improvement = potential_rate - current_rate
                
                total_current += current_filled
                total_potential += potential_filled
                
                report += f"""
üìä {col}
   Avant: {current_rate:5.1f}% ({current_filled:,}/{result['file_info']['total_rows']:,})
   Apr√®s: {potential_rate:5.1f}% ({potential_filled:,}/{result['file_info']['total_rows']:,})
   Gain:  +{improvement:4.1f}% (+{data['estimated_gain']:,} valeurs)
"""
            
            # Statistiques globales
            avg_current = (total_current / len(opportunities)) / result['file_info']['total_rows'] * 100
            avg_potential = (total_potential / len(opportunities)) / result['file_info']['total_rows'] * 100
            
            report += f"""
üéØ IMPACT GLOBAL DE L'ENRICHISSEMENT
{'='*70}
  Compl√©tion moyenne actuelle: {avg_current:.1f}%
  Compl√©tion moyenne projet√©e: {avg_potential:.1f}%
  Am√©lioration globale: +{avg_potential - avg_current:.1f}%
  
  Valeurs totales r√©cup√©rables: {sum(data['estimated_gain'] for data in opportunities.values()):,}
  Temps estim√©: {max(1, sum(data['estimated_gain'] for data in opportunities.values()) // 60)} minutes
"""
            
            # ROI de l'enrichissement
            total_gain = sum(data['estimated_gain'] for data in opportunities.values())
            if total_gain > 0:
                report += f"""
üí∞ RETOUR SUR INVESTISSEMENT
{'='*70}
  Donn√©es actuelles: {sum(result['file_info']['total_rows'] - data['missing_count'] for data in opportunities.values()):,}
  Donn√©es apr√®s enrichissement: {sum(result['file_info']['total_rows'] - data['missing_count'] + data['estimated_gain'] for data in opportunities.values()):,}
  Multiplication par: {(sum(result['file_info']['total_rows'] - data['missing_count'] + data['estimated_gain'] for data in opportunities.values()) / max(1, sum(result['file_info']['total_rows'] - data['missing_count'] for data in opportunities.values()))):.1f}x
"""
        else:
            report += """
‚úÖ AUCUN ENRICHISSEMENT N√âCESSAIRE
{'='*70}
Vos donn√©es sont d√©j√† tr√®s compl√®tes ! Pas d'am√©lioration significative possible.
"""
        
        return report
        
    except Exception as e:
        return f"‚ùå ERREUR: {str(e)}"

# ============================================================================
# ENDPOINTS AGENT IA - √Ä ajouter dans mcp_server/main.py
# ============================================================================

@app.post("/ai-agent/enrich")
async def run_ai_agent_enrichment(
    sample_size: int = Query(10, description="Nombre d'entreprises √† traiter"),
    quality_threshold: int = Query(85, description="Seuil de qualit√© minimum (%)"),
    test_mode: bool = Query(True, description="Mode test s√©curis√©")
):
    """
    ü§ñ Lance l'Agent IA autonome d'enrichissement
    """
    try:
        # S√©curit√© mode test
        if test_mode and sample_size > 50:
            return {
                "error": "Mode test limit√© √† 50 entreprises maximum",
                "suggestion": "D√©sactiver test_mode pour traitement plus large"
            }
        
        # Import direct du fichier ai_agent.py (CORRIG√â)
        import os
        import importlib.util
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        agent_path = os.path.join(current_dir, "tools", "ai_agent.py")
        
        if not os.path.exists(agent_path):
            return {
                "error": "Agent IA non trouv√©",
                "solution": "Cr√©ez le fichier mcp_server/tools/ai_agent.py",
                "path_checked": agent_path
            }
        
        # Charger le module ai_agent dynamiquement
        spec = importlib.util.spec_from_file_location("ai_agent", agent_path)
        ai_agent_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(ai_agent_module)
        
        # Lancer l'enrichissement IA
        result = ai_agent_module.run_ai_enrichment_agent(sample_size)
        
        return result
        
    except Exception as e:
        return {
            "error": f"Erreur Agent IA: {str(e)}",
            "error_type": type(e).__name__,
            "current_dir": os.path.dirname(os.path.abspath(__file__)),
            "suggestion": "V√©rifiez que ai_agent.py existe dans tools/ et contient run_ai_enrichment_agent()"
        }

@app.get("/ai-agent/report", response_class=PlainTextResponse)
async def ai_agent_detailed_report(session_id: str = Query(None, description="ID de session sp√©cifique")):
    """
    üìä Rapport d√©taill√© de la derni√®re ex√©cution de l'Agent IA
    """
    try:
        # Si pas de session_id, prendre la plus r√©cente
        if not session_id:
            # Chercher le log le plus r√©cent
            log_dir = Path("logs")
            if log_dir.exists():
                log_files = list(log_dir.glob("ai_agent_*.log"))
                if log_files:
                    latest_log = max(log_files, key=lambda f: f.stat().st_mtime)
                    session_id = latest_log.stem.replace("ai_agent_", "")
        
        if not session_id:
            return "‚ùå Aucune session Agent IA trouv√©e. Lancez d'abord l'enrichissement."
        
        # Lire le fichier de log
        log_file = Path(f"logs/ai_agent_{session_id}.log")
        
        if not log_file.exists():
            return f"‚ùå Log de session {session_id} non trouv√©."
        
        # G√©n√©rer le rapport depuis les logs
        with open(log_file, 'r', encoding='utf-8') as f:
            log_content = f.read()
        
        # Parser les informations cl√©s du log
        report = f"""
ü§ñ RAPPORT D√âTAILL√â AGENT IA - SESSION {session_id}
{'='*70}

üìä R√âSUM√â EX√âCUTION
"""
        
        # Extraire les m√©triques du log
        lines = log_content.split('\n')
        
        # Statistiques de base
        processed_count = len([line for line in lines if "Traitement:" in line])
        success_count = len([line for line in lines if "‚úÖ Succ√®s - Score:" in line])
        failure_count = len([line for line in lines if "‚ùå √âchec - Raison:" in line])
        
        success_rate = (success_count / processed_count * 100) if processed_count > 0 else 0
        
        report += f"""
  Entreprises trait√©es: {processed_count}
  Enrichissements r√©ussis: {success_count}
  √âchecs: {failure_count}
  Taux de succ√®s: {success_rate:.1f}%

üîç D√âTAIL DES TRAITEMENTS
{'='*70}
"""
        
        # Extraire les d√©tails de chaque traitement
        current_company = ""
        for line in lines:
            if "Traitement:" in line:
                company_name = line.split("Traitement: ")[1] if "Traitement: " in line else "N/A"
                current_company = company_name
                report += f"\nüè¢ {company_name}\n"
            elif "‚úÖ Succ√®s - Score:" in line:
                score = line.split("Score: ")[1].replace("%", "") if "Score: " in line else "N/A"
                report += f"   ‚úÖ ENRICHI - Qualit√©: {score}%\n"
            elif "‚ùå √âchec - Raison:" in line:
                reason = line.split("Raison: ")[1] if "Raison: " in line else "Raison inconnue"
                report += f"   ‚ùå √âCHEC - {reason}\n"
        
        # Chercher les erreurs sp√©cifiques
        error_lines = [line for line in lines if "‚ùå" in line or "ERROR" in line]
        
        if error_lines:
            report += f"""
‚ö†Ô∏è ERREURS D√âTECT√âES
{'='*70}
"""
            for error in error_lines[:10]:  # Limiter √† 10 erreurs
                clean_error = error.split(" - ")[-1] if " - " in error else error
                report += f"‚Ä¢ {clean_error}\n"
        
        # Informations de performance
        start_lines = [line for line in lines if "D√©marrage Agent IA" in line]
        end_lines = [line for line in lines if "Enrichissement termin√©" in line]
        
        if start_lines and end_lines:
            report += f"""
‚ö° PERFORMANCE
{'='*70}
  D√©but: {start_lines[0].split(' - ')[0] if ' - ' in start_lines[0] else 'N/A'}
  Fin: {end_lines[0].split(' - ')[0] if ' - ' in end_lines[0] else 'N/A'}
"""
        
        # Recommandations bas√©es sur les r√©sultats
        report += f"""
üí° RECOMMANDATIONS
{'='*70}
"""
        
        if success_rate >= 80:
            report += "‚úÖ Excellent taux de succ√®s ! Pr√™t pour fichier complet.\n"
        elif success_rate >= 60:
            report += "üü° Bon taux de succ√®s. Quelques optimisations possibles.\n"
        else:
            report += "üî¥ Taux de succ√®s faible. Revoir la strat√©gie de recherche.\n"
        
        if failure_count > 0:
            report += f"‚ö†Ô∏è Analyser les {failure_count} √©checs pour optimiser l'algorithme.\n"
        
        report += """
üöÄ PROCHAINES √âTAPES
{'='*70}
1. Analyser les r√©sultats dans data/processed/
2. Ajuster les param√®tres si n√©cessaire
3. Lancer l'enrichissement sur fichier complet
4. Valider manuellement un √©chantillon des r√©sultats

üìÅ FICHIERS G√âN√âR√âS
{'='*70}"""
        
        # Chercher les fichiers g√©n√©r√©s
        processed_dir = Path("data/processed")
        if processed_dir.exists():
            generated_files = list(processed_dir.glob(f"*{session_id}*"))
            if generated_files:
                for file in generated_files:
                    report += f"\nüìÑ {file.name} ({file.stat().st_size / 1024:.1f} KB)"
            else:
                report += "\n‚ö†Ô∏è Aucun fichier trouv√© dans data/processed/"
        
        report += f"""

üîó COMMANDES UTILES
{'='*70}
  Relancer agent: curl -X POST "http://localhost:8080/ai-agent/enrich?sample_size=10"
  Voir logs: cat logs/ai_agent_{session_id}.log
  Analyse fichier: curl http://localhost:8080/analyze-complete

üéâ RAPPORT TERMIN√â
"""
        
        return report
        
    except Exception as e:
        return f"""
‚ùå ERREUR G√âN√âRATION RAPPORT
{'='*40}
Erreur: {str(e)}

Suggestions:
- V√©rifiez que l'agent IA a bien √©t√© ex√©cut√©
- Contr√¥lez l'existence du dossier logs/
- Relancez l'enrichissement si n√©cessaire
"""

@app.post("/ai-agent/enrich-stream")
async def run_ai_agent_with_streaming(
    sample_size: int = Query(10, description="Nombre d'entreprises √† traiter"),
    test_mode: bool = Query(True, description="Mode test s√©curis√©")
):
    """
    ü§ñ Agent IA avec progression temps r√©el via Server-Sent Events
    Utilisable avec: curl -N http://localhost:8080/ai-agent/enrich-stream?sample_size=10
    """
    
    async def progress_stream():
        """G√©n√©rateur de progression temps r√©el"""
        
        try:
            # S√©curit√© mode test
            if test_mode and sample_size > 50:
                yield f"data: {json.dumps({'error': 'Mode test limit√© √† 50 entreprises'})}\n\n"
                return
            
            # Message de d√©marrage
            yield f"data: {json.dumps({'type': 'start', 'message': f'üöÄ D√©marrage enrichissement {sample_size} entreprises', 'timestamp': time.time()})}\n\n"
            
            # Import de l'agent IA
            yield f"data: {json.dumps({'type': 'info', 'message': 'üìÅ Chargement fichier de donn√©es...', 'timestamp': time.time()})}\n\n"
            
            import os
            import importlib.util
            
            current_dir = os.path.dirname(os.path.abspath(__file__))
            agent_path = os.path.join(current_dir, "tools", "ai_agent.py")
            
            if not os.path.exists(agent_path):
                yield f"data: {json.dumps({'type': 'error', 'message': '‚ùå Agent IA non trouv√©', 'timestamp': time.time()})}\n\n"
                return
            
            # Charger l'agent IA
            spec = importlib.util.spec_from_file_location("ai_agent", agent_path)
            ai_agent_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(ai_agent_module)
            
            yield f"data: {json.dumps({'type': 'info', 'message': 'ü§ñ Agent IA initialis√©', 'timestamp': time.time()})}\n\n"
            
            # Cr√©er l'agent avec callback de progression
            agent = ai_agent_module.AIEnrichmentAgent()
            
            # Simuler l'enrichissement avec progression
            for i in range(sample_size):
                company_name = f"Entreprise_{i+1}"
                
                # Simulation traitement
                yield f"data: {json.dumps({'type': 'progress', 'current': i+1, 'total': sample_size, 'percentage': round((i+1)/sample_size*100, 1), 'message': f'üîç Traitement: {company_name}', 'timestamp': time.time()})}\n\n"
                
                # Simuler temps de traitement
                await asyncio.sleep(2)  # 2 secondes par entreprise
                
                # R√©sultat (simulation 70% succ√®s)
                success = (i % 3) != 0  # 2/3 succ√®s
                status = "‚úÖ Enrichi" if success else "‚ùå √âchec"
                
                yield f"data: {json.dumps({'type': 'result', 'current': i+1, 'total': sample_size, 'success': success, 'message': f'{status} - {company_name}', 'timestamp': time.time()})}\n\n"
            
            # R√©sultat final
            success_count = int(sample_size * 0.7)  # 70% de succ√®s
            
            final_result = {
                'type': 'completed',
                'message': 'üéâ Enrichissement termin√© !',
                'summary': {
                    'total_processed': sample_size,
                    'successful': success_count,
                    'failed': sample_size - success_count,
                    'success_rate': f"{(success_count/sample_size*100):.1f}%"
                },
                'timestamp': time.time()
            }
            
            yield f"data: {json.dumps(final_result)}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': f'‚ùå Erreur: {str(e)}', 'timestamp': time.time()})}\n\n"
    
    return StreamingResponse(
        progress_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Nginx bypass
        }
    )

@app.post("/ai-agent/enrich-real-stream")
async def run_real_ai_agent_with_streaming(
    sample_size: int = Query(10, description="Nombre d'entreprises √† traiter"),
    quality_threshold: int = Query(85, description="Seuil de qualit√© minimum (%)"),
    test_mode: bool = Query(True, description="Mode test s√©curis√©")
):
    """
    ü§ñ Agent IA R√âEL avec progression temps r√©el dans le client Python
    """
    
    # G√©n√©rer un ID de session unique
    import uuid
    session_id = str(uuid.uuid4())[:8]
    
    # Cr√©er une queue pour cette session
    progress_queue = queue.Queue()
    progress_updates[session_id] = progress_queue
    
    async def real_enrichment_stream():
        """Stream qui combine le vrai Agent IA avec la progression"""
        
        try:
            # S√©curit√© mode test
            if test_mode and sample_size > 50:
                yield f"data: {json.dumps({'type': 'error', 'message': 'Mode test limit√© √† 50 entreprises'})}\n\n"
                return
            
            # Message de d√©marrage
            yield f"data: {json.dumps({'type': 'start', 'message': f'üöÄ D√©marrage VRAI enrichissement {sample_size} entreprises', 'session': session_id, 'timestamp': time.time()})}\n\n"
            
            # Import de l'agent IA R√âEL
            yield f"data: {json.dumps({'type': 'info', 'message': 'üìÅ Chargement Agent IA...', 'timestamp': time.time()})}\n\n"
            
            import os
            import importlib.util
            
            current_dir = os.path.dirname(os.path.abspath(__file__))
            agent_path = os.path.join(current_dir, "tools", "ai_agent.py")
            
            if not os.path.exists(agent_path):
                yield f"data: {json.dumps({'type': 'error', 'message': '‚ùå Agent IA non trouv√©', 'timestamp': time.time()})}\n\n"
                return
            
            # Charger l'agent IA R√âEL
            spec = importlib.util.spec_from_file_location("ai_agent", agent_path)
            ai_agent_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(ai_agent_module)
            
            yield f"data: {json.dumps({'type': 'info', 'message': 'ü§ñ Agent IA r√©el initialis√©', 'timestamp': time.time()})}\n\n"
            
            # Lancer l'Agent IA R√âEL dans un thread avec callback
            loop = asyncio.get_event_loop()
            
            def run_real_agent_with_progress():
                """Ex√©cute le vrai agent IA avec callbacks de progression"""
                
                # Cr√©er l'agent avec callbacks
                agent = ai_agent_module.AIEnrichmentAgent()
                
                # Patcher la m√©thode d'enrichissement pour r√©cup√©rer la progression
                original_enrich = agent._enrich_companies_ai
                
                def enrichment_with_callbacks(sample_df):
                    """Version avec callbacks pour le streaming"""
                    
                    results = {
                        "processed": 0,
                        "enriched": 0,
                        "failed": 0,
                        "enrichment_data": {},
                        "quality_reports": {},
                        "ai_decisions": []
                    }
                    
                    for idx, (_, company) in enumerate(sample_df.iterrows(), 1):
                        start_time = time.time()
                        company_name = company.get('Nom courant/D√©nomination', f'Entreprise_{idx}')
                        
                        # Envoyer progression au stream
                        progress_queue.put({
                            'type': 'progress',
                            'current': idx,
                            'total': len(sample_df),
                            'percentage': round((idx / len(sample_df)) * 100, 1),
                            'message': f'üîç Traitement: {company_name[:30]}...',
                            'timestamp': time.time()
                        })
                        
                        try:
                            # VRAI enrichissement de l'entreprise
                            enrichment_result = agent._enrich_single_company_ai(company, idx)
                            
                            processing_time = time.time() - start_time
                            
                            if enrichment_result["success"]:
                                results["enriched"] += 1
                                results["enrichment_data"][str(idx)] = enrichment_result["data"]
                                results["quality_reports"][str(idx)] = enrichment_result["quality_report"]
                                agent.performance_metrics["quality_scores"].append(enrichment_result["quality_score"])
                                
                                # Envoyer r√©sultat succ√®s
                                progress_queue.put({
                                    'type': 'result',
                                    'current': idx,
                                    'total': len(sample_df),
                                    'success': True,
                                    'message': f'‚úÖ Enrichi - {company_name[:30]} (Score: {enrichment_result["quality_score"]}%)',
                                    'data': {
                                        'website': enrichment_result["data"].get("website", "N/A"),
                                        'quality_score': enrichment_result["quality_score"]
                                    },
                                    'timestamp': time.time()
                                })
                                
                            else:
                                results["failed"] += 1
                                agent.performance_metrics["error_details"].append({
                                    "company_index": idx,
                                    "company_name": company_name,
                                    "error_reason": enrichment_result["error_reason"]
                                })
                                
                                # Envoyer r√©sultat √©chec
                                progress_queue.put({
                                    'type': 'result',
                                    'current': idx,
                                    'total': len(sample_df),
                                    'success': False,
                                    'message': f'‚ùå √âchec - {company_name[:30]} ({enrichment_result["error_reason"]})',
                                    'timestamp': time.time()
                                })
                            
                            results["processed"] += 1
                            results["ai_decisions"].append(enrichment_result["ai_decision_log"])
                            
                            # Rate limiting (r√©duit pour les tests)
                            time.sleep(1)  # 1 seconde au lieu de 3
                            
                        except Exception as e:
                            results["failed"] += 1
                            results["processed"] += 1
                            
                            progress_queue.put({
                                'type': 'result',
                                'current': idx,
                                'total': len(sample_df),
                                'success': False,
                                'message': f'‚ùå Erreur - {company_name[:30]} ({str(e)})',
                                'timestamp': time.time()
                            })
                    
                    return results
                
                # Remplacer temporairement la m√©thode
                agent._enrich_companies_ai = enrichment_with_callbacks
                
                # Lancer l'enrichissement R√âEL
                return agent.enrich_sample(sample_size)
            
            # Ex√©cuter dans un thread pool
            with ThreadPoolExecutor(max_workers=1) as executor:
                # Lancer l'agent en arri√®re-plan
                future = loop.run_in_executor(executor, run_real_agent_with_progress)
                
                # Stream les updates de progression
                while not future.done():
                    try:
                        # R√©cup√©rer les updates avec timeout
                        update = progress_queue.get(timeout=0.5)
                        yield f"data: {json.dumps(update)}\n\n"
                    except queue.Empty:
                        # Envoyer un heartbeat
                        yield f"data: {json.dumps({'type': 'heartbeat', 'timestamp': time.time()})}\n\n"
                    
                    await asyncio.sleep(0.1)  # Petit d√©lai
                
                # R√©cup√©rer le r√©sultat final
                final_result = await future
                
                # Vider la queue restante
                while not progress_queue.empty():
                    try:
                        update = progress_queue.get_nowait()
                        yield f"data: {json.dumps(update)}\n\n"
                    except queue.Empty:
                        break
                
                # Envoyer le r√©sultat final
                if "error" not in final_result:
                    completion_data = {
                        'type': 'completed',
                        'message': 'üéâ Enrichissement R√âEL termin√© !',
                        'summary': final_result["execution_summary"],
                        'output_file': final_result.get("output_file", "N/A"),
                        'session_id': final_result["session_id"],
                        'timestamp': time.time()
                    }
                else:
                    completion_data = {
                        'type': 'error',
                        'message': f'‚ùå Erreur finale: {final_result["error"]}',
                        'timestamp': time.time()
                    }
                
                yield f"data: {json.dumps(completion_data)}\n\n"
        
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': f'‚ùå Erreur streaming: {str(e)}', 'timestamp': time.time()})}\n\n"
        
        finally:
            # Nettoyer la queue
            if session_id in progress_updates:
                del progress_updates[session_id]
    
    return StreamingResponse(
        real_enrichment_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.get("/ai-agent/status")
async def ai_agent_status():
    """
    üìä Statut en temps r√©el de l'Agent IA
    """
    try:
        # Chercher les logs r√©cents
        log_dir = Path("logs")
        
        if not log_dir.exists():
            return {
                "status": "inactive",
                "message": "Aucune activit√© Agent IA d√©tect√©e",
                "suggestion": "Lancez un enrichissement avec /ai-agent/enrich"
            }
        
        # Trouver le log le plus r√©cent
        log_files = list(log_dir.glob("ai_agent_*.log"))
        
        if not log_files:
            return {
                "status": "inactive", 
                "message": "Aucun log Agent IA trouv√©",
                "available_commands": {
                    "start_enrichment": "POST /ai-agent/enrich",
                    "view_analysis": "GET /analyze-complete"
                }
            }
        
        # Analyser le log le plus r√©cent
        latest_log = max(log_files, key=lambda f: f.stat().st_mtime)
        session_id = latest_log.stem.replace("ai_agent_", "")
        
        # Lire les derni√®res lignes pour d√©terminer le statut
        with open(latest_log, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.split('\n')
        last_lines = [line for line in lines[-10:] if line.strip()]
        
        # D√©terminer le statut
        if any("Enrichissement termin√©" in line for line in last_lines):
            status = "completed"
        elif any("D√©but enrichissement IA" in line for line in last_lines):
            status = "running"
        else:
            status = "unknown"
        
        # Extraire les m√©triques
        processed = len([line for line in lines if "Traitement:" in line])
        success = len([line for line in lines if "‚úÖ Succ√®s" in line])
        
        return {
            "status": status,
            "latest_session": session_id,
            "last_activity": latest_log.stat().st_mtime,
            "quick_metrics": {
                "companies_processed": processed,
                "successful_enrichments": success,
                "success_rate": f"{(success/processed*100):.1f}%" if processed > 0 else "0%"
            },
            "available_actions": {
                "view_detailed_report": f"GET /ai-agent/report?session_id={session_id}",
                "start_new_enrichment": "POST /ai-agent/enrich",
                "check_results": f"Check data/processed/ for files with {session_id}"
            }
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "suggestion": "V√©rifiez la configuration de l'Agent IA"
        }

@app.get("/ai-agent/test-import")
async def test_ai_agent_import():
    """
    üß™ Test simple pour v√©rifier que l'agent IA peut √™tre import√©
    """
    try:
        import os
        import importlib.util
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        agent_path = os.path.join(current_dir, "tools", "ai_agent.py")
        
        # V√©rifications √©tape par √©tape
        checks = {
            "file_exists": os.path.exists(agent_path),
            "file_path": agent_path,
            "tools_dir_exists": os.path.exists(os.path.join(current_dir, "tools")),
            "tools_dir_content": []
        }
        
        # Lister le contenu du dossier tools
        tools_dir = os.path.join(current_dir, "tools")
        if os.path.exists(tools_dir):
            checks["tools_dir_content"] = os.listdir(tools_dir)
        
        # Essayer d'importer si le fichier existe
        if checks["file_exists"]:
            try:
                spec = importlib.util.spec_from_file_location("ai_agent", agent_path)
                ai_agent_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(ai_agent_module)
                
                # V√©rifier que la fonction principale existe
                has_main_function = hasattr(ai_agent_module, 'run_ai_enrichment_agent')
                
                checks.update({
                    "import_successful": True,
                    "has_main_function": has_main_function,
                    "available_functions": [attr for attr in dir(ai_agent_module) if not attr.startswith('_')]
                })
                
                if has_main_function:
                    checks["status"] = "‚úÖ Agent IA pr√™t"
                else:
                    checks["status"] = "‚ö†Ô∏è Agent IA import√© mais fonction principale manquante"
                
            except Exception as import_error:
                checks.update({
                    "import_successful": False,
                    "import_error": str(import_error),
                    "status": "‚ùå Erreur d'import"
                })
        else:
            checks["status"] = "‚ùå Fichier ai_agent.py non trouv√©"
        
        return checks
        
    except Exception as e:
        return {
            "error": f"Erreur test import: {str(e)}",
            "error_type": type(e).__name__
        }


if __name__ == "__main__":
    port = int(os.getenv("SERVER_PORT", 8080))
    host = os.getenv("SERVER_HOST", "localhost")
    debug = os.getenv("DEBUG", "true").lower() == "true"
    
    print(f"üöÄ D√©marrage du serveur MCP Marne & Gondoire v0.2.0")
    print(f"üìç Adresse: http://{host}:{port}")
    print(f"üìö Documentation: http://{host}:{port}/docs")
    print(f"üîç Health check: http://{host}:{port}/health")
    print(f"üìä Analyse (basique): http://{host}:{port}/analyze")
    print(f"üß™ Test basic: http://{host}:{port}/test-basic")
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=debug,
        log_level="info" if debug else "warning"
    )
